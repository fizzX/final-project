---
title: "Calculations"
author: "Kayla Manning"
date: "4/7/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(broom)
library(infer)

tidy_int_reg_bag <- read_csv("all_tidy.csv",
                             col_types = cols(col_date(format = ''),
                                             col_character(),
                                             col_character(),
                                             col_character(),
                                             col_character(),
                                             col_character(),
                                             col_double()))

```

```{r sd_total_swipes}

# looking at the standard deviation from year to year
# this is the grand total of swipes (resident, interhouse, etc.) at lunch for
# each house

tidy_int_reg_bag %>% 
  group_by(year, meal, house, type) %>% 
  filter(meal != "Brain Break",
         type == "grand_total",
         meal == "Lunch") %>% 
  summarise(iqr = IQR(count, na.rm = TRUE)) %>% 
  arrange(desc(iqr)) %>% 
  select(year, house, iqr) %>% 
  pivot_wider(names_from = year, values_from = iqr) %>% 
  mutate(iqr_increase = `1819` - `1718`) %>% 
  arrange(desc(iqr_increase))

```

```{r model_counts_by_house_day}

# overall, Tuesday has most swipes, while Saturday & Friday (intercept) have the
# least; Sunday is the only day without a significant difference from Friday
# swipe counts

tidy_int_reg_bag %>% 
  lm(count ~ day, data = .) %>% 
  tidy() %>%
  arrange(desc(estimate)) %>% 
  filter(p.value < 0.05)

# now looking at counts of interhouse swipes by days of the week; Wednesday has
# most interhouse swipes, while Saturday, Friday, and Sunday have the least
# Sunday has an insignificant difference from the baseline of Friday

tidy_int_reg_bag %>% 
  filter(type == "int") %>% 
  lm(count ~ day, data = .) %>% 
  tidy() %>% 
  arrange(desc(estimate)) %>% 
  filter(p.value < 0.05)

# interhouse swipes by meal; dinner actually has most 

tidy_int_reg_bag %>% 
  filter(type == "int",
         meal != "Day Total") %>% 
  lm(count ~ meal, data = .) %>% 
  tidy()

# lunch interhouse swipes by house

tidy_int_reg_bag %>% 
  filter(type == "int",
         meal == "Lunch",
         house != "FlyBy",
         house != "Hillel") %>% 
  lm(count ~ house, data = .) %>% 
  tidy() %>% 
  arrange(desc(estimate))

# lunch interhouse swipes by year; insignificant increase overall

tidy_int_reg_bag %>% 
  filter(type == "int",
         meal == "Lunch",
         house != "FlyBy",
         house != "Hillel") %>% 
  lm(count ~ year, data = .) %>% 
  tidy() %>% 
  arrange(desc(estimate))

# will look at fitted values for predicting average number of interhouse swipes
# in each house for each year and then calculated the difference between these
# two fitted values

tidy_int_reg_bag %>% 
  filter(type == "int",
         meal == "Lunch",
         house != "FlyBy",
         house != "Hillel") %>% 
  lm(count ~ year * house, data = .) %>% 
  augment() %>% 
  group_by(year, house) %>% 
  summarize(fitted = mean(.fitted)) %>% 
  arrange(desc(fitted)) %>% 
  pivot_wider(names_from = year, values_from = fitted) %>% 
  mutate(increase = `1819` - `1718`) %>% 
  arrange(desc(increase))

```

```{r trying_to_bootstrap}

# I want to create a function that randomly assigns a certain count of swipes to
# each house and then calculate the percentage that are interhouse. Then, I will
# plot the simulated distribution of interhouse swipes and then a line with the
# actual total interhouse swipes

set.seed(2020)
nreps <- 500

pct_int <- tidy_int_reg_bag %>% 
  filter(type %in% c("int", "grand_total")) %>% 
  pivot_wider(names_from = type, values_from = count) %>% 
  mutate(pct_int = int / grand_total * 100) %>% 
  select(house, year, pct_int)

boot <- tidy_int_reg_bag %>% 
  rep_sample_n(size = nrow(.), replace = TRUE, reps = nreps) %>% 
  group_by(replicate, type) %>% 
  summarise(avg_count = mean(count, na.rm = TRUE)) %>% 
  pivot_wider(names_from = type, values_from = avg_count) %>% 
  mutate(pct_int = int / grand_total * 100)

boot %>% 
  ggplot(aes(pct_int)) +
  geom_histogram(bins = 50) +
  scale_x_continuous() +
  geom_vline(xintercept = mean(pct_int %>% 
                                 filter(house == "Lowell") %>% 
                                 pull(pct_int), na.rm = TRUE),
             color = "blue") +
  geom_vline(xintercept = mean(pct_int %>% 
                                 filter(house == "Adams") %>% 
                                 pull(pct_int), na.rm = TRUE),
             color = "red") +
  geom_vline(xintercept = mean(pct_int %>% 
                                 filter(house == "Currier") %>% 
                                 pull(pct_int), na.rm = TRUE),
             color = "green") 



```


```{r trying_to_bootstrap_again}

# first I want to find how many interhouse diners there are on any given day in
# each house ; will use lunch as meal of interest. there are 372 unique dates in
# my data set, so I want to randomly selected that many rows for each replicate
# and then randomly assign a house to each proportion.

set.seed(2019)

houses <- unique(tidy_int_reg_bag$house)

pct <- tidy_int_reg_bag %>% 
  filter(meal == "Lunch",
         type %in% c("int", "grand_total")) %>% 
  group_by(date, type, house) %>% 
  summarise(day_total = sum(count, na.rm = TRUE)) %>% 
  pivot_wider(names_from = type, values_from = day_total) %>% 
  mutate(pct_int = int / grand_total * 100) 

pct %>% 
  select(date, pct_int) %>% 
  rep_sample_n(size = 372, replace = TRUE, reps = nreps) %>% 
  ungroup() %>% 
  mutate(houses = sample(houses, size = nrow(.), replace = TRUE)) %>% 
  
  # now I'm grouping by replicate and house to find the average percent of
  # interhouse diners in each house for each replicate
  
  group_by(replicate, houses) %>% 
  summarise(avg_pct_int = mean(pct_int, na.rm = TRUE)) %>% 
  
  # will add a column with the true average percentage of interhouse diners from
  # the original dataset so I can easily plot a vertical line on each of the
  # histograms that I'm about to generate
  
  mutate(actual_pct_int = pct %>% 
           group_by(house) %>% 
           summarise(actual_pct_int = mean(pct_int, na.rm = TRUE)) %>% 
           pull(actual_pct_int)) %>% 
  
  # next, I want to plot the values for each house on a histogram, with a
  # vertical line for the actual percent of interhouse diners for each house
  
  ggplot(aes(avg_pct_int, fill = houses)) +
  geom_histogram() +
  facet_wrap(~ houses) +
  
  # now adding/fixing labels to make the plot more appealing
  
  labs(title = "Bootstrapped Percentages of Interhouse versus Actual Percentages",
       fill = "Houses") +
  ylab("Count") +
  xlab("Simulated Median Percentage of Interhouse Swipes")
  
  

```



```{r currier_discussion_calculations}

# looking at the difference in grand_total median swipe counts between the two years

tidy_int_reg_bag %>% 
  filter(meal == "Lunch",
         house == "Currier",
         type == "grand_total") %>% 
  group_by(year) %>% 
  summarise(median = median(count)) %>% 
  pivot_wider(names_from = year, values_from = median) %>% 
  summarise(diff = `1819` - `1718`)

# now doing the same but for interhouse median swipe counts

tidy_int_reg_bag %>% 
  filter(meal == "Lunch",
         house == "Currier",
         type == "int") %>% 
  group_by(year) %>% 
  summarise(median = median(count, na.rm = TRUE)) %>% 
  pivot_wider(names_from = year, values_from = median) %>% 
  summarise(diff = `1819` - `1718`)

```

